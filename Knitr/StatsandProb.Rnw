\documentclass[12pt, a4paper, oneside]{article} % Paper size, default font size and one-sided paper
%\graphicspath{{./Figures/}} % Specifies the directory where pictures are stored
%\usepackage[dcucite]{harvard}
\usepackage{amsmath}
\usepackage{setspace}
\usepackage{pdflscape}
\usepackage{rotating}
\usepackage[flushleft]{threeparttable}
\usepackage{multirow}
\usepackage[comma, sort&compress]{natbib}% Use the natbib reference package - read up on this to edit the reference style; if you want text (e.g. Smith et al., 2012) for the in-text references (instead of numbers), remove 'numbers' 
\usepackage{graphicx}
%\bibliographystyle{plainnat}
\bibliographystyle{agsm}
\usepackage[colorlinks = true, citecolor = blue, linkcolor = blue]{hyperref}
%\hypersetup{urlcolor=blue, colorlinks=true} % Colors hyperlinks in blue - change to black if annoying
%\renewcommand[\harvardurl]{URL: \url}
\begin{document}
\title{Stats and Probability Information}
%\author{Rob Hayward\footnote{University of Brighton Business School, Lewes Road, Brighton, BN2 4AT; Telephone 01273 642586.  rh49@brighton.ac.uk}}
\date{\today}
\maketitle
\section*{Continuous and marginal distributions}

The marginal distribution of $x$ in a two-variable distribution is equal to the sum of the joint distribution over $y$. 
\begin{equation}
Pr(X = x) = \sum_y Pr(X = x, Y = y) = \sum_y Pr(X = x|Y = y)Pr(Y = y)
\end{equation}

From \href{http://en.wikipedia.org/wiki/Marginal_distribution}{Wikipedia}

For the continuous case
\begin{equation}
p_X(x) = \int_y p_{X,Y}(x,y)dy = \int_y p_{X|Y}(x|y)p_Y(y)dy
\end{equation}

There are three related distributions:  the marginal, the joint and the conditional. 

\section{Mixture Model}
This is a probabilistic model that relates some random variables to some other variables.  The model has sub-populations. The properties of the sub-population are different from those of the parent. The sub-populations may not be observable.  For example, the distribution of returns may be different in different sub-population or regime. 

A \emph{mixture distribution} is the probability distribution of a random variable  whose values are derived from an underlying set of random variables. The \emph{mixture components} are individual distributions with \emph{mixture weights}.  Even in cases where the mixture comonents have a normal distribution, the mixture distribution is likely to be non-normal. Mixture models are used to understand the sub-population when there is only access to the information about the pooled population. 

The mixture model will be comprised of N random varibles distributed according to K components, with each component belonging to the same distribution. The k mixture weights sum to one. Each component will have parameters (mean and variance in the case of normal distribution).  

The method will try to estimate the all the parameters of the model from the data.  The underlying data is known $(x_i)$; the number of mixture components is set $(K)$; the parameters of the distribution of each mixture component $(\theta_{i=1\dots K})$; mixture weight $(\Phi_{i = 1\dots K})$; $\mathbf{\Phi}$ K-dimensional vector summing to 1; $F(x|\theta)$ probability distribution of observations parameterised on $\theta$; $\alpha$ shared hyperparameter for component weights; $\beta$ shared hyperparameter for mixture weights; $H(\theta|\alpha)$ prior probability distribution of component parameters; 

\section{Adjusted R squared}
\href{http://davegiles.blogspot.ca/2013/05/when-will-adjusted-r-squared-increase.html}{Adjusted R squared} applied a penalty to the basic R squard to account for additional variables.  The equartion is 

\begin{equation}
R_A^2 = 1 - \left [ \frac{(n-1)}{(n-k)} \right ] [1 - R^2]
\end{equation}

Adding a regressor to the equation will increase (reduce)) the $R_A^"$ when the absolute value of the t-statistic is greater (less) than one. Adding a group of regressors to the model will reduce (increase) the $R_A^"$ when the absolute value of the F-statistic is greater than one.  

Proof \href{http://davegiles.blogspot.com/2014/04/proof-of-result-about-adjusted.html}{http://davegiles.blogspot.com/2014/04/proof-of-result-about-adjusted.html}


\section{Monte Carlo Simulation}
This comes from \href{http://blog.revolutionanalytics.com/2014/04/quantitative-finance-applications-in-r-5.html}{Revoluitionary Analytics}.  The analysis is in annual terms.  

\begin{equation}
\mu \Delta t + \sigma Z \sqrt{\Delta t}
\end{equation}

where $\mu$ is the drift or average annual return, Z is a standard Normal random variable, t is measured in years so for monthly returns $\Delta t$ equals $\frac{1}{12}$.

<<MC, fig.height=6, cache=TRUE>>=
n <- 10000
# Fixing the seed gives us a consistent set of simulated returns
set.seed(106)
z <- rnorm(n)        # mean = 0 and sd = 1 are defaults
mu <- 0.10
sd <- 0.15
delta_t <- 0.25
# apply to expression (*) above
qtr_returns <- mu*delta_t + sd*z*sqrt(delta_t)
hist(qtr_returns, breaks = 100, col = "green")
@

Now the descriptive statistics can be uncovered from the simulated results. 
<<stats>>=
stats <- c(mean(qtr_returns) * 4, sd(qtr_returns) * 2)   # sqrt(4)
names(stats) <- c("mean", "volatility")
stats
@
This is the basic model.  It would also be possible to simulate two variables and to include some relationship between the two in the analysis.  It would also be possible to simulate an asset in two different regimes. A Monte-Carlo Markov Model (MCMM) would require another set of $\mu$ and $\sigma$ inputs as well as a transition matrix of the probabilities that there is a switch from one regime to another. 
 
\section{Generalised Lambda Distribution}
This is from \href{http://blog.revolutionanalytics.com/2014/02/quantitative-finance-applications-in-r-4-using-the-generalized-lambda-distribution-to-simulate-market-returns.html}{Revolutionary Analytics}.  The four parameters $\lambda_1$, $\lambda_2$, $\lambda_3$ and $\lambda_4$ indicate the location, scale, skew and kurtosis of the distribution. 

<<Lambda, warning=FALSE, message=FALSE, cache=TRUE>>=
require(GLDEX)
require(quantmod)

getSymbols("SPY", from = "1994-02-01")  
SPY.Close <- SPY[,4] # Closing prices

SPY.vector <- as.vector(SPY.Close)

# Calculate log returns
sp500 <- diff(log(SPY.vector), lag = 1)
sp500 <- sp500[-1] # Remove the NA in the first position
# Set normalise="Y" so that kurtosis is calculated with
# reference to kurtosis = 0 under Normal distribution
fun.moments.r(sp500, normalise = "Y")
@
Now fit the GLD with the function fun.data.fit.mm. There are warnings but these can be ignored. 

<<GLD, warning=FALSE, message=FALSE, fig.height=6, cache=TRUE>>=
spLambdaDist = fun.data.fit.mm(sp500)
spLambdaDist
fun.plot.fit(fit.obj = spLambdaDist, data = sp500, nclass = 100,
             param = c("rs", "fmkl"), xlab = "Returns")
@
Now it is possible to generrate simualted results using the function rgl(). Lambdas need to be identified. 
<<Lambda2>>=
lambda_params_rs <- spLambdaDist[, 1]
lambda1_rs <- lambda_params_rs[1]
lambda2_rs <- lambda_params_rs[2]
lambda3_rs <- lambda_params_rs[3]
lambda4_rs <- lambda_params_rs[4]

lambda_params_fmkl <- spLambdaDist[, 2]
lambda1_fmkl <- lambda_params_fmkl[1]
lambda2_fmkl <- lambda_params_fmkl[2]
lambda3_fmkl <- lambda_params_fmkl[3]
lambda4_fmkl <- lambda_params_fmkl[4]
@
Now generate simulations of each variety. 

There are problems with the rgl function.  I am not sure what this does.  It is 10 million simulations.  I think that the rgl just uses extra hardware to make the change. It may be useful to re-do this last section using a different method. 
<<simulat2e, warning=FALSE, error=FALSE>>=
require(gld)
require(GLDEX)
# RS version:
set.seed(100)    # Set seed to obtain a reproducible set
rs_sample <- rgl(n = 10000000, lambda1=lambda1_rs, lambda2 = lambda2_rs,
                  lambda3 = lambda3_rs,
                  lambda4 = lambda4_rs,param = "rs")

# Moments of simulated returns using RS method:
fun.moments.r(rs_sample, normalise="Y")

# Moments calculated from market data:
fun.moments.r(sp500, normalise="Y")

# FKML version:
set.seed(100)    # Set seed to obtain a reproducible set
fmkl_sample <- rgl(n = 100000, lambda1=lambda1_fmkl, lambda2 =                                lambda2_fmkl,lambda3 = lambda3_fmkl,
                   lambda4 = lambda4_fmkl,param = "fmkl")

# Moments of simulated returns using FMKL method:
fun.moments.r(fmkl_sample, normalise="Y")

# Moments calculated from market data:
fun.moments.r(sp500, normalise="Y") 
@
Compare the moments to the S\&P500 market data
<<Simulate>>=
fun.moments.r(rs_sample, normalise="Y")
fun.moments.r(sp500, normalise="Y")
fun.moments.r(fmkl_sample, normalise="Y")
fun.moments.r(sp500, normalise="Y")
@
\section{Lasso method}
\href{http://www.mathtube.org/lecture/video/lasso-brief-review-and-new-significance-test#.U1aODV1sp94.twitter}{Rob Tibshirani}Cancer example that requires identification of appropriate cell. There are 20 cases that are being used as a training set.  Train a classifier to identify whether the cells are cencerous or not.  There are 11,000 features. It would be useful to use as few of the features as possible. Therefore, also want to know which features are important for the classification. 

Sparcity means that the features are reduced by only using those that pass a particular level of significance.  \href{http://statweb.stanford.edu/~tibs/lasso.html}{More here.}
\end{document}